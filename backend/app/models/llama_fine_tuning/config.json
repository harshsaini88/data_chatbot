{
    "model_name": "memory_improvement_qlora",
    "base_model": "meta-llama/Llama-2-7b-hf",
    "training_config": {
        "quantization": "4bit",
        "lora_rank": 16,
        "lora_alpha": 32,
        "learning_rate": 2e-4,
        "batch_size": 4,
        "epochs": 3,
        "max_sequence_length": 512
    }
}